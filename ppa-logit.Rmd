---
title: "PPA-logit"
author: "Emily Branch"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Required packages
library(tidyverse)
library(sf)
library(leaflet)
library(lubridate)
library(scales)
library(jsonlite)
library(viridis)
library(htmlwidgets)
library(nnet)
library(caret)
library(MLmetrics)

# Read and clean stations data
stations <- read_csv("data/stations.csv") %>%
  select(URI, name, `country-code`, longitude, latitude, avg_stop_times) %>%
  mutate(
    name = gsub("/.*", "", name),
    station_id = gsub("http://irail.be/stations/NMBS/", "", URI)
  )

# Function to safely process one JSON line
process_json_line <- function(line) {
  tryCatch({
    # Parse JSON string
    data <- fromJSON(line)
    
    # Extract relevant fields and return as tibble
    tibble(
      timestamp = ymd_hms(data$querytime),
      from_station = gsub("http://irail.be/stations/NMBS/", "", data$post$from),
      vehicle = gsub("http://irail.be/vehicle/", "", data$post$vehicle),
      occupancy = gsub("http://api.irail.be/terms/", "", data$post$occupancy),
      to_station = gsub("http://irail.be/stations/NMBS/", "", data$post$to),
      date = as.Date(data$querytime),
      weekday = wday(ymd_hms(data$querytime), label = TRUE),
      hour = hour(ymd_hms(data$querytime))
    )
  }, error = function(e) {
    # Return NULL for any problematic lines
    NULL
  })
}

# Read and process occupancy data
occupancy_lines <- readLines("data/occupancy-until-20161029.txt")
occupancy_data <- do.call(rbind, lapply(occupancy_lines, process_json_line)) %>%
  as_tibble() %>%
  filter(!is.na(timestamp))
```

```{r}

occupancy_data <- occupancy_data %>%
  mutate(
    occupancy_numeric = case_when(
      occupancy == "low" ~ 0,
      occupancy == "medium" ~ 0.5,
      occupancy == "high" ~ 1
    ),
    month = month(timestamp, label = TRUE),
    is_weekend = if_else((weekdays(timestamp)== "Sunday")| (weekdays(timestamp)== "Saturday"), 1, 0)
  )

occup_stations <- left_join(occupancy_data, stations, by = c("from_station" = "station_id")) %>%
  rename("lat_from" = latitude,
         "lon_from" = longitude,
         "avg_stop_from" = avg_stop_times,
         "name_from" = name)

occup_stations <- left_join(occup_stations, select(stations, "station_id", "latitude", "longitude", "avg_stop_times", "name"), by = c("to_station" = "station_id")) %>%
  rename("lat_to" = latitude,
         "lon_to" = longitude,
         "avg_stop_to" = avg_stop_times,
         "name_to" = name)

occupancy_bin <- occup_stations %>%
  mutate(interval60 = floor_date(ymd_hms(timestamp), unit = "hour"),
         interval15 = floor_date(ymd_hms(timestamp), unit = "15 mins"),
         week = week(interval60),
         dotw = wday(interval60, label=TRUE))

occupancy_bin <- occupancy_bin %>%
  arrange(timestamp) %>%
  group_by(from_station, to_station) %>% # Group by OD pairs if needed
  mutate(
    lag_occupancy_1 = lag(occupancy_numeric, 1),
    lag_occupancy_2 = lag(occupancy_numeric, 2)
  ) %>%
  ungroup()
```

```{r}
data.Train <- filter(occupancy_bin, week >= 38)
data.Test <- filter(occupancy_bin, week < 38)
data.Train <- na.omit(data.Train)

fit <- glm(
  occupancy_numeric ~ timestamp+ avg_stop_to + avg_stop_from + name_from + name_to + vehicle + lag_occupancy_1 + lag_occupancy_2 + is_weekend, #distance?
  data = data.Train,
  family = binomial(link = "logit")
)


```
```{r}
data.Train <- data.Train %>%
  mutate(predicted_prob = predict(fit, type = "response"))
```
```{r}
# Define thresholds
low_threshold <- 0.25
high_threshold <- 0.75

# Categorize into Low, Medium, High
data.Train <- data.Train %>%
  mutate(
    occupancy_category = case_when(
      predicted_prob <= low_threshold ~ "low",
      predicted_prob > low_threshold & predicted_prob <= high_threshold ~ "medium",
      predicted_prob > high_threshold ~ "high"
    )
  )

```

```{r}
# Simulate observed categories
data.Train <- data.Train %>%
  mutate(
    observed_category = case_when(
      occupancy_numeric <= low_threshold ~ "low",
      occupancy_numeric > low_threshold & occupancy_numeric <= high_threshold ~ "medium",
      occupancy_numeric > high_threshold ~ "high"
    )
  )

# Confusion matrix
confusion_matrix <- table(data.Train$observed_category, data.Train$occupancy_category)
print(confusion_matrix)

# Calculate overall accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)

```
```{r}
# lets try multinom
data.Train$occupancy_category <- as.factor(data.Train$occupancy_category)

# Train multinomial regression model
fit_multinom <- multinom(occupancy ~ timestamp + name_from + name_to + lag_occupancy_1 +lag_occupancy_2 + avg_stop_from, data = data.Train)

data.Train <- data.Train %>%
  mutate(predicted_probs = predict(fit_multinom, newdata = ., type = "probs"))

levels(data.Train$occupancy) <- levels(data.Train$predicted_class)

data.Train <- data.Train %>%
  mutate(predicted_class = predict(fit_multinom, newdata = ., type = "class"))

levels(data.Train$occupancy) <- levels(data.Train$predicted_class)

data.Train$occupancy <- factor(data.Train$occupancy, levels = c("low", "medium", "high"))
data.Train$predicted_class <- factor(data.Train$predicted_class, levels = c("low", "medium", "high"))
confusionMatrix(data.Train$predicted_class, data.Train$occupancy)

```
```{r}

train_control <- trainControl(
  method = "cv",               # Cross-validation
  number = 10,                 # Number of folds (you can adjust this)
  classProbs = TRUE,           # We need class probabilities for performance metrics
  summaryFunction = multiClassSummary,  # Use multi-class metrics like F1, accuracy
  savePredictions = "final",   # Save the predictions for each fold
  sampling = "up"              # Stratified sampling to handle imbalanced classes
)

# Train the multinomial logistic regression model
model <- train(
  occupancy_category ~ .,     # Formula for predicting occupancy category
  data = data.Train,                # Data for training
  method = "nnet",            # Method for multinomial regression
  trControl = train_control,  # Cross-validation settings
  trace = FALSE,              # Disable iteration messages
  linout = TRUE,              # Ensures we use the multinomial output format
  tuneGrid = expand.grid(size = c(5, 10), decay = c(0.1, 0.5))  # Tuning hidden units and decay
)           # Ensures we use the multinomial output format
)
```



